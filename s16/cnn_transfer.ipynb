{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torchvision\n",
    "\n",
    "[torchvision](https://github.com/pytorch/vision) - библиотека, содержащая популярные CV датасеты, утилиты для препроцессинга и, самое важное, pre-trained модели для классификации, обученные на [ImageNet](http://image-net.org/).\n",
    "\n",
    "Большая часть потребностей покрывается имеющимися моделями, но если нужна какая-то другая архитектура или нужно решать задачу, отличную от классификации, то хорошую реализацию и веса, скорее всего, получится нагуглить или найти на github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/brodt/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "model.train(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как достать признаки?\n",
    "\n",
    "- переопределить последний слой так, чтобы он ничего не делал (неплохой вариант, но что, если нужны признаки из внутрненнего слоя?)\n",
    "- написать хук, который будет возвращать признаки (хороший вариант)\n",
    "- покромсать сетку и делать forward pass только для тех слоев, которые нужны (плохой вариант)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Способ 1. Переопределить последний слой\n",
    "\n",
    "***ВНИМАНИЕ 1:*** Серьезная проблема `torchvision` - отсутствие единого интерфейса у моделей. В каждой реализации слои имеют разные имена и при единовременной работе с разными моделями приходится писать обвязку из условий. Если использовать реализации других архитектур, то ситуация только ухудшается\n",
    "\n",
    "***ВНИМАНИЕ 2:*** В отличие от **Keras**, в **PyTorch** не принято делать последним слоем активацию. Нужная функция применяется при написании train / inference кода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "features_model = deepcopy(model)\n",
    "\n",
    "features_model.fc = nn.Identity()\n",
    "\n",
    "dummy_x = torch.randn(1, 3, 224, 224)\n",
    "features = features_model(dummy_x)\n",
    "features_shape = features.data.numpy().shape\n",
    "assert features_shape == (1, 2048), 'expected (1, 2048), but real is {}'.format(features_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Способ 2. Forward hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgpool_features = None\n",
    "\n",
    "def get_features(module, inputs, output):\n",
    "    global avgpool_features   \n",
    "    avgpool_features = np.squeeze(output.data.cpu().numpy(), axis=(2, 3))\n",
    "\n",
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "model.avgpool.register_forward_hook(get_features)\n",
    "\n",
    "dummy_x = torch.randn(1, 3, 224, 224)\n",
    "model(dummy_x)\n",
    "\n",
    "assert avgpool_features.shape == (1, 2048), 'expected (1, 2048), but real is {}'.format(avgpool_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение на признаках\n",
    "\n",
    "Обучим обычный sklearn-классификатор, которому на вход подадим признаки из нейросети\n",
    "\n",
    "В качестве датасета будем использовать данные конкурса https://www.kaggle.com/c/dogs-vs-cats/data, https://www.tensorflow.org/datasets/catalog/cats_vs_dogs\n",
    "\n",
    "Датасет содержит 25000 изображений кошек и собак, по 12500 каждого класса. Задача: определить, к какому классу относится конкретное изображение\n",
    "\n",
    "Для определения качества моделей будем использовать метрику ROC-AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачаем и подготовим данные. Выделим 30% на валидацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘kagglecatsanddogs_3367a.zip’ already there; not retrieving.\n",
      "\n",
      "Archive:  kagglecatsanddogs_3367a.zip\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
    "!unzip -f kagglecatsanddogs_3367a.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('PetImages')\n",
    "cat_fnames = [str(p) for p in (data_path / 'Cat').glob('*.jpg')][:1000]\n",
    "dog_fnames = [str(p) for p in (data_path / 'Dog').glob('*.jpg')][:1000]\n",
    "all_names = cat_fnames + dog_fnames\n",
    "labels = np.array([0] * len(cat_fnames) + [1] * len(dog_fnames))\n",
    "\n",
    "train_fnames, val_fnames, y_train, y_val = train_test_split(\n",
    "    all_names, labels, test_size=0.3,\n",
    "    random_state=42, shuffle=True, stratify=labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В **PyTorch** можно удобно работать с данными с помощью классов `Dataset` и `DataLoader`\n",
    "\n",
    "Напишем свой датасет для расчет признаков изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, fnames, shape):\n",
    "        self._fnames = fnames\n",
    "        self._transform = torchvision.transforms.Compose([\n",
    "            \n",
    "            torchvision.transforms.Resize(shape),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fname = self._fnames[index]\n",
    "        img = Image.open(fname).convert('RGB')\n",
    "        img = self._transform(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._fnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно как-то рассчитать признаки.\n",
    "\n",
    "Воспользуемся способом с хуком, но чтобы обойтись без глобальной переменной реализуем класс `FeatureExtractor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(self, model, device='cuda'):\n",
    "        self._model = model\n",
    "        self._avgpool_features = None\n",
    "        self._device = device\n",
    "        self._model.avgpool.register_forward_hook(self._get_features)\n",
    "\n",
    "    def get_dataset_features(self, loader):\n",
    "        self._model.eval().to(self._device)\n",
    "        features = []\n",
    "        with tqdm.tqdm(loader) as pbar:\n",
    "            for sample in pbar:\n",
    "                _ = self._model(sample.to(self._device))\n",
    "                features.append(self._avgpool_features)\n",
    "\n",
    "        return np.concatenate(features)\n",
    "\n",
    "    def _get_features(self, module, inputs, output):\n",
    "        self._avgpool_features = np.squeeze(output.data.cpu().numpy(), axis=(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:16<00:00, 10.37it/s]\n",
      "100%|██████████| 75/75 [00:05<00:00, 12.78it/s]\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "batch_size = 8\n",
    "num_workers = 0\n",
    "shape = (224, 224)\n",
    "\n",
    "train_dataset = FeaturesDataset(train_fnames, shape)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "val_dataset = FeaturesDataset(val_fnames, shape)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "extractor = FeatureExtractor(model, device='cuda')\n",
    "\n",
    "train_features = extractor.get_dataset_features(train_loader)\n",
    "val_features = extractor.get_dataset_features(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно взять любой из известных классификаторов и подать найденные признаки на вход\n",
    "\n",
    "Должен получитсься очень хороший ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_auc(y_val, y_pred, model_name):\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    plt.plot(*roc_curve(y_val, y_pred)[:2], label='{} AUC={:.4f}'.format(model_name, auc))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], '--', color='black')\n",
    "    plt.legend(fontsize='large')\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict_proba(val_features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_auc(y_val, y_pred, model_name='RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем добиться лучшего качества модели путем ее дообучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetFinetune(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResnetFinetune, self).__init__()\n",
    "        self.net = torchvision.models.resnet50(pretrained=True)\n",
    "        self.net.fc = nn.Sequential(\n",
    "            nn.Linear(self.net.fc.in_features, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def fresh_parameters(self):\n",
    "        return self.net.fc.parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatsDogsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, fnames, labels, shape):\n",
    "        self._fnames = fnames\n",
    "        self._labels = labels\n",
    "        self._shape = shape\n",
    "        self._transform = torchvision.transforms.Compose([\n",
    "            \n",
    "            torchvision.transforms.Resize(shape),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fname = self._fnames[index]\n",
    "        img = Image.open(fname).convert('RGB')\n",
    "        img = self._transform(img)\n",
    "\n",
    "        return img, self._labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correct(y_true, y_pred):\n",
    "    correct = (y_true == y_pred).squeeze()\n",
    "\n",
    "    return correct.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:    \n",
    "    def __init__(self, model, criterion, config, device='cuda'):\n",
    "        self._model = model\n",
    "        self._device = device\n",
    "        self._criterion = criterion\n",
    "        self._epochs = config['epochs']\n",
    "\n",
    "        if config['only_top']:\n",
    "            self._optimizer = torch.optim.Adam(self._model.fresh_parameters(), lr=config['lr'])\n",
    "        else:\n",
    "            self._optimizer = torch.optim.Adam(self._model.parameters(), lr=config['lr'])        \n",
    "\n",
    "        self._model.to(self._device)\n",
    "\n",
    "    def fit(self, train_loader, val_loader):\n",
    "        for epoch in range(self._epochs):\n",
    "            self._model.train()\n",
    "            train_loss, train_accuracy = self._run_epoch(epoch, train_loader, is_training=True)\n",
    "            print('Train. loss: {}, accuracy: {}'.format(train_loss, train_accuracy))\n",
    "            \n",
    "            self._model.eval()\n",
    "            val_loss, val_accuracy = self._run_epoch(epoch, val_loader, is_training=False)\n",
    "            print('Validation. loss: {}, accuracy: {}'.format(val_loss, val_accuracy))\n",
    "\n",
    "    def _run_epoch(self, epoch, loader, is_training):\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        if is_training:\n",
    "            pbar = tqdm.tqdm(enumerate(loader), total=len(loader), desc='Epoch {}'.format(epoch), ncols=0)\n",
    "        else:\n",
    "            pbar = tqdm.tqdm(enumerate(loader), total=len(loader), desc='Val', ncols=0)\n",
    "        \n",
    "        for i, data in pbar:\n",
    "            batch_loss, batch_correct = self._step(data, is_training)\n",
    "            loss += batch_loss\n",
    "            correct += batch_correct\n",
    "        \n",
    "        pbar.close()\n",
    "        loss /= len(loader)\n",
    "        accuracy = correct / len(loader.dataset)\n",
    "\n",
    "        return loss, accuracy\n",
    "    \n",
    "    def _step(self, data, is_training=True):\n",
    "        images = data[0].to(self._device)\n",
    "        y_true = data[1].to(self._device)\n",
    "\n",
    "        if is_training:\n",
    "            self._optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(is_training):\n",
    "            y_pred = self._model(images)\n",
    "            y_pred = y_pred.squeeze()\n",
    "            loss = self._criterion(y_pred, y_true.float())\n",
    "\n",
    "            if is_training:\n",
    "                loss.backward()\n",
    "                self._optimizer.step()\n",
    "            \n",
    "        probas = torch.sigmoid(y_pred)\n",
    "        labels = (probas > 0.5).int()\n",
    "        correct = calculate_correct(y_true=y_true, y_pred=labels)\n",
    "\n",
    "        return loss.item(), correct.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала будем учить только добавленные нами слои"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResnetFinetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_workers = 16\n",
    "shape = (224, 224)\n",
    "\n",
    "train_dataset = CatsDogsDataset(train_fnames, y_train, shape)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "val_dataset = CatsDogsDataset(val_fnames, y_val, shape)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100% 175/175 [00:17<00:00,  9.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.24778537273939166, accuracy: 0.9021428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100% 75/75 [00:03<00:00, 20.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.07164867898449302, accuracy: 0.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: 100% 175/175 [00:15<00:00, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.22794825091958046, accuracy: 0.915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100% 75/75 [00:03<00:00, 22.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.06944021385783951, accuracy: 0.9683333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: 100% 175/175 [00:16<00:00, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.14804290534529302, accuracy: 0.9357142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100% 75/75 [00:03<00:00, 24.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.061137053314596415, accuracy: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: 100% 175/175 [00:16<00:00, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.19095617460219988, accuracy: 0.9214285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100% 75/75 [00:03<00:00, 22.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.11780826086178423, accuracy: 0.9416666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: 100% 175/175 [00:17<00:00, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.17596098390540907, accuracy: 0.9328571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100% 75/75 [00:03<00:00, 19.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.060930774739633, accuracy: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: 100% 175/175 [00:17<00:00, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.18434089341333934, accuracy: 0.9335714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100% 75/75 [00:03<00:00, 19.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.054271285771392286, accuracy: 0.9833333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: 100% 175/175 [00:16<00:00, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.12059623373406274, accuracy: 0.9535714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100% 75/75 [00:03<00:00, 21.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.04924239155836403, accuracy: 0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: 100% 175/175 [00:08<00:00, 21.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.14417325918695756, accuracy: 0.9442857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100% 75/75 [00:01<00:00, 58.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.053371913465671245, accuracy: 0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: 100% 175/175 [00:09<00:00, 19.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.1433140024988513, accuracy: 0.9414285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100% 75/75 [00:01<00:00, 41.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.05723620865494013, accuracy: 0.9816666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100% 175/175 [00:06<00:00, 27.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.1121165022054421, accuracy: 0.9528571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100% 75/75 [00:01<00:00, 61.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.09300291570369154, accuracy: 0.9683333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'lr': 1e-3,\n",
    "    'epochs': 10,\n",
    "    'only_top': True\n",
    "}\n",
    "\n",
    "trainer = Trainer(model, nn.BCEWithLogitsLoss(), config, device='cuda')\n",
    "trainer.fit(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:    \n",
    "    def __init__(self, model, device='cuda'):\n",
    "        self._model = model\n",
    "        self._device = device\n",
    "\n",
    "    def predict(self, loader):\n",
    "        y_pred = []\n",
    "        self._model.eval().to(self._device)\n",
    "        \n",
    "        with tqdm.tqdm(enumerate(loader), total=len(loader)) as pbar:\n",
    "            for i, data in pbar:\n",
    "                batch_pred = self._step(data)\n",
    "                y_pred.append(batch_pred)\n",
    "        \n",
    "        return np.concatenate(y_pred)\n",
    "    \n",
    "    def _step(self, data, is_training=True):\n",
    "        images = data[0].to(self._device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_pred = self._model(images)\n",
    "        \n",
    "        y_pred = y_pred.squeeze()\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "\n",
    "        return y_pred.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:01<00:00, 61.55it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(model, device='cuda')\n",
    "y_pred = evaluator.predict(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_auc(y_val, y_pred, model_name='Resnet finetuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь разморозим все веса и обучим несколько эпох с низким *learning rate*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100% 175/175 [00:07<00:00, 23.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.18902099441150702, accuracy: 0.9342857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100% 75/75 [00:01<00:00, 60.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.07569044085170996, accuracy: 0.9683333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: 100% 175/175 [00:07<00:00, 23.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.08330785403418954, accuracy: 0.9735714285714285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100% 75/75 [00:01<00:00, 60.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.10580281167730694, accuracy: 0.9616666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: 100% 175/175 [00:07<00:00, 23.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.08512207465944811, accuracy: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100% 75/75 [00:01<00:00, 60.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.08198225962696597, accuracy: 0.9716666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: 100% 175/175 [00:07<00:00, 23.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.048803403805941344, accuracy: 0.9821428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100% 75/75 [00:02<00:00, 37.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.11389998279133579, accuracy: 0.9566666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: 100% 175/175 [00:17<00:00,  9.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.08133836602642466, accuracy: 0.9778571428571429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100% 75/75 [00:03<00:00, 22.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.09400841382953028, accuracy: 0.9683333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: 100% 175/175 [00:19<00:00,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.04701064771207582, accuracy: 0.9857142857142858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100% 75/75 [00:03<00:00, 19.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.0702537158979491, accuracy: 0.9816666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: 100% 175/175 [00:20<00:00,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.025091064075906097, accuracy: 0.9914285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100% 75/75 [00:02<00:00, 25.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.12389849128123993, accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: 100% 175/175 [00:18<00:00,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.020629134737246205, accuracy: 0.9921428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100% 75/75 [00:03<00:00, 21.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.09539426567653815, accuracy: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: 100% 175/175 [00:20<00:00,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.02325049689430411, accuracy: 0.9928571428571429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100% 75/75 [00:02<00:00, 25.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.25250882597174495, accuracy: 0.9333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100% 175/175 [00:19<00:00,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.044986735980658395, accuracy: 0.9885714285714285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100% 75/75 [00:03<00:00, 22.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation. loss: 0.12341284257165777, accuracy: 0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'lr': 1e-4,\n",
    "    'epochs': 10,\n",
    "    'only_top': False\n",
    "}\n",
    "\n",
    "trainer = Trainer(model, nn.BCEWithLogitsLoss(), config, device='cuda')\n",
    "trainer.fit(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:03<00:00, 21.63it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(model, device='cuda')\n",
    "y_pred = evaluator.predict(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_auc(y_val, y_pred, model_name='Resnet finetuned no freeze')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пишем свою CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Типичные ошибки\n",
    "\n",
    "Рассмотрим несколько примеров архитектур в связке с функциями потерь и попробуем найти какие-то проблемы\n",
    "\n",
    "Для простоты будем использовать `nn.Sequential`\n",
    "\n",
    "#### Задача 1\n",
    "\n",
    "Предсказать стоимость автомобиля, на вход 100 признаков, описывающих автомобиль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.BatchNorm2d(num_features=100),\n",
    "    nn.Linear(in_features=3, out_features=256),\n",
    "    nn.Linear(in_features=256, out_features=256),\n",
    "    nn.Linear(in_features=256, out_features=1)\n",
    ")\n",
    "\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача 2\n",
    "\n",
    "MNIST: Распознать рукописную цифру (0-9), на вход ч/б картинка 28x28 пикселей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=512, kernel_size=(3, 3)),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d((2, 2)),\n",
    "    \n",
    "    nn.Conv2d(in_channels=512, out_channels=256, kernel_size=(3, 3)),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d((2, 2)),\n",
    "\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=256, out_features=100),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    \n",
    "    nn.Linear(in_features=100, out_features=10),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Dropout(0.1)\n",
    ")\n",
    "\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача 3\n",
    "\n",
    "Бинарная классификация изображений, на вход картинка RGB 100x100 пикселей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(10, 10)),\n",
    "    nn.Softmax(),\n",
    "    nn.MaxPool2d((6, 6)),\n",
    "    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(10, 10)),\n",
    "    nn.Softmax(),\n",
    "    nn.MaxPool2d((6, 6)),\n",
    "    nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(10, 10)),\n",
    "    nn.Softmax(),\n",
    "    nn.MaxPool2d((6, 6)),\n",
    "    \n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=128, out_features=256),\n",
    "    nn.Softmax(),\n",
    "    nn.Dropout(0.8),\n",
    "    nn.Linear(in_features=256, out_features=1)\n",
    ")\n",
    "\n",
    "loss = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST\n",
    "\n",
    "Напишем свою сетку для решения задачи распознавания рукописных чисел\n",
    "\n",
    "Датасет содержит ч/б изображения размером 28x28 пикселей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем `early_stopping` и попробуем `lr_scheduler.ReduceLROnPlateau`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTTrainer:    \n",
    "    def __init__(self, model, criterion, config, device='cuda'):\n",
    "        self._model = model\n",
    "        self._device = device\n",
    "        self._criterion = criterion\n",
    "        \n",
    "        self._model.to(self._device)\n",
    "        \n",
    "        self._epochs = config['epochs']\n",
    "        self._early_stopping = config['early_stopping']\n",
    "              \n",
    "        self._optimizer = torch.optim.Adam(self._model.parameters(), lr=config['lr'])\n",
    "        self._scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self._optimizer,\n",
    "            'min',\n",
    "            factor=config['lr_reduce_rate'],\n",
    "            patience=config['patience'],\n",
    "            verbose=True,\n",
    "        )\n",
    "        \n",
    "        self._best_loss = float('inf')\n",
    "        self._best_epoch = -1\n",
    "\n",
    "    def fit(self, train_loader, val_loader):\n",
    "        for epoch in range(self._epochs):\n",
    "            self._model.train()\n",
    "            train_loss, train_accuracy = self._run_epoch(epoch, train_loader, is_training=True)\n",
    "            print('Train. loss: {}, accuracy: {}'.format(train_loss, train_accuracy))\n",
    "            \n",
    "            self._model.eval()\n",
    "            val_loss, val_accuracy = self._run_epoch(epoch, val_loader, is_training=False)\n",
    "            print('Validation. loss: {}, accuracy: {}'.format(val_loss, val_accuracy))\n",
    "\n",
    "            self._scheduler.step(val_loss)\n",
    "           \n",
    "            if self._best_loss > val_loss:\n",
    "                self._best_loss = val_loss\n",
    "                self._best_epoch = epoch\n",
    "\n",
    "            if abs(self._best_epoch - epoch) > self._early_stopping:\n",
    "                print('Early stopping. Epoch {}. Best epoch: {}, best {}: {}'.format(epoch, self._best_epoch))\n",
    "                break\n",
    "    \n",
    "    def _run_epoch(self, epoch, loader, is_training):\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        if is_training:\n",
    "            pbar = tqdm.tqdm(enumerate(loader), total=len(loader), desc='Epoch {}'.format(epoch))\n",
    "        else:\n",
    "            pbar = enumerate(loader)\n",
    "        \n",
    "        for i, data in pbar:\n",
    "            batch_loss, batch_correct = self._step(data, is_training)\n",
    "            loss += batch_loss\n",
    "            correct += batch_correct\n",
    "        \n",
    "        if is_training:\n",
    "            pbar.close()\n",
    "\n",
    "        loss /= len(loader)\n",
    "        accuracy = correct / len(loader.dataset)\n",
    "\n",
    "        return loss, accuracy\n",
    "    \n",
    "    def _step(self, data, is_training=True):\n",
    "        metrics_values = {}\n",
    "        images = data[0].to(self._device)\n",
    "        y_true = data[1].to(self._device)\n",
    "\n",
    "        if is_training:\n",
    "            self._optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(is_training):\n",
    "            y_pred = self._model(images)\n",
    "            y_pred = y_pred.squeeze()\n",
    "            loss = self._criterion(y_pred, y_true)\n",
    "\n",
    "            if is_training:\n",
    "                loss.backward()\n",
    "                self._optimizer.step()\n",
    "            \n",
    "        probas = torch.softmax(y_pred, dim=0)\n",
    "        labels = probas.max(1)[1]\n",
    "        correct = calculate_correct(y_true=y_true, y_pred=labels)\n",
    "\n",
    "        return loss.item(), correct.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool2d((2, 2))\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3))\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3))\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3))\n",
    "        self.drop = nn.Dropout2d(p=0.5)\n",
    "\n",
    "        self.classifier = nn.Linear(in_features=128, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.drop(x)\n",
    "    \n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9913344it [00:22, 449213.67it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29696it [00:00, 152991.88it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1649664it [00:03, 449096.37it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5120it [00:00, 145398.90it/s]           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_workers = 0\n",
    "\n",
    "\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomRotation(degrees=(-10, 10)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='data', train=True, download=True, transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "val_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "val_dataset = torchvision.datasets.MNIST(root='data', train=False, download=False, transform=val_transform)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 938/938 [00:14<00:00, 66.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.5654107260503876, accuracy: 0.6929\n",
      "Validation. loss: 0.12951385536806503, accuracy: 0.928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 938/938 [00:11<00:00, 78.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.20541971304348663, accuracy: 0.8125333333333333\n",
      "Validation. loss: 0.06578892760963481, accuracy: 0.9516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 938/938 [00:12<00:00, 76.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.155115340352813, accuracy: 0.83745\n",
      "Validation. loss: 0.055052219955495314, accuracy: 0.9575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 938/938 [00:11<00:00, 79.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.12814172511217373, accuracy: 0.85595\n",
      "Validation. loss: 0.048204503620616575, accuracy: 0.9662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 938/938 [00:17<00:00, 54.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.10926461348762867, accuracy: 0.8623833333333333\n",
      "Validation. loss: 0.04156194742449046, accuracy: 0.9644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 938/938 [00:23<00:00, 40.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.09724246522437519, accuracy: 0.8686666666666667\n",
      "Validation. loss: 0.03334266416550815, accuracy: 0.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 938/938 [00:25<00:00, 36.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.08792565622752203, accuracy: 0.8802666666666666\n",
      "Validation. loss: 0.03420238669708284, accuracy: 0.9739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 938/938 [00:24<00:00, 38.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.07999234328042469, accuracy: 0.8859333333333334\n",
      "Validation. loss: 0.029978728971991296, accuracy: 0.9769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 938/938 [00:25<00:00, 37.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.07626914339058641, accuracy: 0.8914666666666666\n",
      "Validation. loss: 0.0323032840074149, accuracy: 0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 938/938 [00:21<00:00, 42.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. loss: 0.0701247787607937, accuracy: 0.8942333333333333\n",
      "Validation. loss: 0.029060680877267542, accuracy: 0.9748\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'lr': 1e-3,\n",
    "    'epochs': 10,\n",
    "    'early_stopping': 5,\n",
    "    'lr_reduce_rate': 0.5,\n",
    "    'patience': 3\n",
    "}\n",
    "\n",
    "trainer = MNISTTrainer(model, nn.CrossEntropyLoss(), config, device='cuda')\n",
    "trainer.fit(train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
